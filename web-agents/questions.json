[{"short_description": "\r\n            I'm new to using spark and scala but I have to solve the following problem:\nI have one ORC file containing rows which I have to check against a certain condition comming from a hash map.\n\nI build the ...\r\n        ", "title": "How to filter RDD relying on hash map?", "tag": "scala", "answers": 0, "votes": 1, "views": 38, "url": "https://stackoverflow.com/questions/43168016/how-to-filter-rdd-relying-on-hash-map"}, {"short_description": "\r\n            The aim of the method is to take elements in a list until a limit is reached.\n\ne.g. \n\nI've come up with 2 different implementations  \n\ndef take(l: List[Int], limit: Int): List[Int] = {\n  var sum = 0\n  ...\r\n        ", "title": "Functional way to take element in a list until a limit in Scala", "tag": "scala", "answers": 0, "votes": 4, "views": 70, "url": "https://stackoverflow.com/questions/43166199/functional-way-to-take-element-in-a-list-until-a-limit-in-scala"}, {"short_description": "\r\n            I might sound silly but I am new to scala so please bear with me.\nI am little confused about using switch case in scala. As per the example of finding the last element of a list\n\nwhat is the letter 'h'...\r\n        ", "title": "Using match .. case in scala", "tag": "scala", "answers": 2, "votes": 0, "views": 49, "url": "https://stackoverflow.com/questions/43165106/using-match-case-in-scala"}, {"short_description": "\r\n            I am a newbie with akka.\nHaving a very simple configuration of one seed node and one non-seed node.\n\nPlease find below, sequence of operation :-\r\n  \n  Seed node started :-\n  \r\nval pConfig = ...\r\n        ", "title": "Akka don't elect existing worker node as seed node, once the seed node is killed", "tag": "scala", "answers": 1, "votes": 0, "views": 23, "url": "https://stackoverflow.com/questions/43164563/akka-dont-elect-existing-worker-node-as-seed-node-once-the-seed-node-is-killed"}, {"short_description": "\r\n            I'm using the Spark ML library for the first time and ran into a roadblock.\nMy data has multiple categorical variables.\nI'm using StringIndexers followed by OneHotEncoders as stages in a pipeline\nI ...\r\n        ", "title": "Having the same one hot encoding on training and testing data using spark ml pipeline [duplicate]", "tag": "scala", "answers": 0, "votes": 0, "views": 20, "url": "https://stackoverflow.com/questions/43163510/having-the-same-one-hot-encoding-on-training-and-testing-data-using-spark-ml-pip"}, {"short_description": "\r\n            Using FakeRequest to test my controller, in what case should I specify uri?\n\nthis is my current fake request:\n\nval request = FakeRequest(POST, \"/\").withHeaders(\"Content-type\" -> \"application/json\")....\r\n        ", "title": "When using play FakeRequest is it better practice specifying the uri?", "tag": "scala", "answers": 1, "votes": 0, "views": 19, "url": "https://stackoverflow.com/questions/43163366/when-using-play-fakerequest-is-it-better-practice-specifying-the-uri"}, {"short_description": "\r\n            In java @Mock annotation can be used like below\n\n@Mock\nprivate InsightHandleProvider handleProvider;\r\nhow to use the same annotation in scala? It gives compilation error when tried to below\n\nclass ...\r\n        ", "title": "How to use mockito mock annotation in scala", "tag": "scala", "answers": 1, "votes": 0, "views": 23, "url": "https://stackoverflow.com/questions/43163066/how-to-use-mockito-mock-annotation-in-scala"}, {"short_description": "\r\n            I need to invoke a generic SAT solver from an application written in Scala. I was looking into SAT4J since it can be easily imported as a jar file however am finding it difficult to actually use it. ...\r\n        ", "title": "Using a SAT solver from Scala class", "tag": "scala", "answers": 0, "votes": 0, "views": 23, "url": "https://stackoverflow.com/questions/43162776/using-a-sat-solver-from-scala-class"}, {"short_description": "\r\n            This is a sample code from a scala book. \nThis object has a method that will remove any html tags in a given string.\nBut for reason, it removes the entire string content not just HTML tags. May i know ...\r\n        ", "title": "Why is this simple regular expression not working", "tag": "scala", "answers": 0, "votes": 0, "views": 38, "url": "https://stackoverflow.com/questions/43162386/why-is-this-simple-regular-expression-not-working"}, {"short_description": "\r\n            Can someone explain why the code below compiles ?\n\nI think it should not compile.\n\nobject RandomExperiments extends App{\n  def takeTuple(t:(Int,Int))=print (s\"$t ${t._1}\\n\")\n  takeTuple(1,3) // this ...\r\n        ", "title": "passing non tuple to (Int,Int)=>() compiles, why?", "tag": "scala", "answers": 0, "votes": 1, "views": 48, "url": "https://stackoverflow.com/questions/43161936/passing-non-tuple-to-int-int-compiles-why"}, {"short_description": "\r\n            I want to write a Scala client that talks a proprietary protocol over a tcp connection with TLS. \n\nBasically, I want to rewrite the following code from Node.js in Scala:\n\nvar conn_options = {\n        ...\r\n        ", "title": "How to open TCP connection with TLS in scala using akka", "tag": "scala", "answers": 0, "votes": 0, "views": 27, "url": "https://stackoverflow.com/questions/43161047/how-to-open-tcp-connection-with-tls-in-scala-using-akka"}, {"short_description": "\r\n            Is there a way to run cucumber from scalatest?\n\nI know running cucumber using junit like below\n\n@RunWith(classOf[Cucumber])\n@CucumberOptions(features = ..., tags = ...)\nclass CucumberStarter\r\nBut I'm ...\r\n        ", "title": "Running cucumber with scalatest", "tag": "scala", "answers": 0, "votes": 0, "views": 18, "url": "https://stackoverflow.com/questions/43160201/running-cucumber-with-scalatest"}, {"short_description": "\r\n            I am new in Spark/Scala world, and I have a question regarding data selection from dataframes.\nI have a table with the following data, and I need to choose for each cust and user_id pair, all the last ...\r\n        ", "title": "How to select the most recent data from dataframe for a pair of keys?", "tag": "scala", "answers": 1, "votes": 0, "views": 21, "url": "https://stackoverflow.com/questions/43160048/how-to-select-the-most-recent-data-from-dataframe-for-a-pair-of-keys"}, {"short_description": "\r\n            Do the Scala and Java versions of Akka share the same code for the actual \"engine\"? I imagine that the difference between them is mainly just hooks into the framework and not large changes in the code ...\r\n        ", "title": "Is the choice of Scala Akka vs Java Akka just a choice of hooks into the framework?", "tag": "scala", "answers": 0, "votes": 1, "views": 45, "url": "https://stackoverflow.com/questions/43160046/is-the-choice-of-scala-akka-vs-java-akka-just-a-choice-of-hooks-into-the-framewo"}, {"short_description": "\r\n            I have a Play app that allows users to log in with social providers, and have authentication set up identically to the Play-Silhouette-Slick seed example. The following code is probably fine, but I ...\r\n        ", "title": "Stateless Silhouette CookieAuthenticator can't find / deletes cookie", "tag": "scala", "answers": 1, "votes": 0, "views": 16, "url": "https://stackoverflow.com/questions/43159309/stateless-silhouette-cookieauthenticator-cant-find-deletes-cookie"}, {"short_description": "\r\n            I can't get scalac working despite scala successfully opening scala> in the terminal. \nI suspect this is something to do with setting scala_home in my .bash_profile, on my mac.\n\nWhat is the correct ...\r\n        ", "title": "Where was scala_home homebrew installed on OSX?", "tag": "scala", "answers": 1, "votes": 0, "views": 27, "url": "https://stackoverflow.com/questions/43159045/where-was-scala-home-homebrew-installed-on-osx"}, {"short_description": "\r\n            I have a 80x50 monochrome terminal I want to render (in Minecraft if that matters). The characters are defined in a tileset that holds 256 char bitmaps. That tileset can be changed. I implemented this ...\r\n        ", "title": "Dynamically render tiles to form a screen with GLSL", "tag": "scala", "answers": 0, "votes": -2, "views": 28, "url": "https://stackoverflow.com/questions/43158304/dynamically-render-tiles-to-form-a-screen-with-glsl"}, {"short_description": "\r\n            let's assume that we have a dataframe like this:\n\n+---------+--------+---+--------+\n|firstName|lastName|age|town    |\n+---------+--------+---+--------+\n|Paul     |barn    |54 |new york|\n|Patrick  |...\r\n        ", "title": "what technologie to develop GUI for Apache Spark [closed]", "tag": "scala", "answers": 0, "votes": -2, "views": 24, "url": "https://stackoverflow.com/questions/43157809/what-technologie-to-develop-gui-for-apache-spark"}, {"short_description": "\r\n            I have a .csv file that contains rows with missing values. Those values instead of null, are denoted by the character ?.\n\nHow can I remove the rows that contain at least one column with value ?, given ...\r\n        ", "title": "Remove rows with missing values denoted by '?'", "tag": "scala", "answers": 2, "votes": 0, "views": 49, "url": "https://stackoverflow.com/questions/43157540/remove-rows-with-missing-values-denoted-by"}, {"short_description": "\r\n            i need to extends SimpleSwingGUIApplication for my GUI application but i have an error :\nnot found : type SimpleSwingGUIApplication\n\nthere is my code :\n\nimport scala.swing._\n\nclass GUI extends ...\r\n        ", "title": "why i can't extends SimpleSwingGUIApplication?", "tag": "scala", "answers": 2, "votes": 0, "views": 15, "url": "https://stackoverflow.com/questions/43157531/why-i-cant-extends-simpleswingguiapplication"}, {"short_description": "\r\n            I need to execute multiple queries through spark sql (sqlcontext). It taking more time and memory then goes to GC memory overhead error due to more shuffling and sorting based on union all. \n\nval ...\r\n        ", "title": "Spark SQL- GC memory overhead exception", "tag": "scala", "answers": 0, "votes": 0, "views": 26, "url": "https://stackoverflow.com/questions/43156902/spark-sql-gc-memory-overhead-exception"}, {"short_description": "\r\n            The following is the output of an operation in Spark 2.1.0\n\nscala> TEMPEdge.take(10)\n17/04/01 17:30:58 WARN Executor: 1 block locks were not released by TID = 299:\n[rdd_36_0]\nres38: Array[org....\r\n        ", "title": "Scala : extracting only the first values from an array of lists", "tag": "scala", "answers": 1, "votes": -1, "views": 55, "url": "https://stackoverflow.com/questions/43156765/scala-extracting-only-the-first-values-from-an-array-of-lists"}, {"short_description": "\r\n            I have:\n\nvar className = \"scala.collection.immutable.List\"\nval clazz = Class.forName(className)\nval value = ArrayBuffer(1, 2, 3)\r\nso the question is how to cast value to class, if className is ...\r\n        ", "title": "Scala class casting", "tag": "scala", "answers": 1, "votes": 0, "views": 54, "url": "https://stackoverflow.com/questions/43156546/scala-class-casting"}, {"short_description": "\r\n            I'm trying to write \"persistence\" module using spring-boot-starter-data-jpa lib. I want to use this module as dependency for other modules:\r\nscala based akka application\nscala play 2.x application\r\n...\r\n        ", "title": "spring-boot-starter-data-jpa module as dependency to other modules", "tag": "scala", "answers": 0, "votes": 0, "views": 19, "url": "https://stackoverflow.com/questions/43156403/spring-boot-starter-data-jpa-module-as-dependency-to-other-modules"}, {"short_description": "\r\n            version := \"1.0\" scalaVersion := \"2.11.8\" ivyScala :=\n  ivyScala.value map { _.copy(overrideScalaVersion = true) }\n  libraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"2.1.0\"\r\nI try to get ...\r\n        ", "title": "\u201cunresolved dependency\u201d for Spark 2.1.0 on SBT", "tag": "scala", "answers": 1, "votes": 1, "views": 34, "url": "https://stackoverflow.com/questions/43155665/unresolved-dependency-for-spark-2-1-0-on-sbt"}, {"short_description": "\r\n            Slick codegen generates an handy Tables.scala with all the classes for the rows and the tables. We like this approach because we can use relational design and exploit the full power of the SQL dialect ...\r\n        ", "title": "Domain classes and slick generated case classes conversion with Shapeless", "tag": "scala", "answers": 1, "votes": 2, "views": 70, "url": "https://stackoverflow.com/questions/43155440/domain-classes-and-slick-generated-case-classes-conversion-with-shapeless"}, {"short_description": "\r\n            I would like to know the complexity of converting scala collection operations like following ones :\n\nList.fill(n)(1).toArray\nArray.fill(n)(1).toList\nArrayBuffer( Array.fill(n)(1):_* )\r\nI suppose that ...\r\n        ", "title": "What is the complexity of converting scala collection from one type to another?", "tag": "scala", "answers": 1, "votes": 0, "views": 30, "url": "https://stackoverflow.com/questions/43154595/what-is-the-complexity-of-converting-scala-collection-from-one-type-to-another"}, {"short_description": "\r\n            I am reading the data[json as String] from kafka queue and tring to parse json as String into case class using liftweb json api.\n\nhere is the code Snippet\n\nval sparkStreamingContext = new ...\r\n        ", "title": "Apache Spark Object not Serializable Exception for json parser", "tag": "scala", "answers": 0, "votes": 2, "views": 42, "url": "https://stackoverflow.com/questions/43153412/apache-spark-object-not-serializable-exception-for-json-parser"}, {"short_description": "\r\n            I have a curried function on the object:\n\nsealed trait Sum[A, B]\n\nfinal case class Left[A, B](value: A) extends Sum[A, B]\n\nfinal case class Right[A, B](value: B) extends Sum[A, B]\n\nobject Sum {\n\n  def ...\r\n        ", "title": "How to use curry function", "tag": "scala", "answers": 0, "votes": 0, "views": 48, "url": "https://stackoverflow.com/questions/43153233/how-to-use-curry-function"}, {"short_description": "\r\n            The defined way to describe an enumeration is the following: \n\nobject Color extends Enumeration{\n  type Color = Value\n  val RED, GREEN, BLUE = Value\n}\r\nWhat I don't understand is the structure of the ...\r\n        ", "title": "In Scala enumerations how does one interpret 'val RED, GREEN, BLUE = Value'?", "tag": "scala", "answers": 1, "votes": 2, "views": 38, "url": "https://stackoverflow.com/questions/43153180/in-scala-enumerations-how-does-one-interpret-val-red-green-blue-value"}, {"short_description": "\r\n            There is a pattern I use often to make code simpler that I like to call a Power Enum which is an enumeration that takes advantage of the visitor pattern as well as carries custom data. Here is an ...\r\n        ", "title": "How can you write a power Enum with visitor semantics in Scala?", "tag": "scala", "answers": 1, "votes": -1, "views": 74, "url": "https://stackoverflow.com/questions/43152963/how-can-you-write-a-power-enum-with-visitor-semantics-in-scala"}, {"short_description": "\r\n            I am using the latest version of the IntelliJ Idea 2017.1\n\nIn my project I have many calls to this function\n\nfoo.bar(x)\n\nI want to search and replace this to x.toFoo\n\nThe problem is that X can be ...\r\n        ", "title": "Search and replace text using Regex in IntelliJ", "tag": "scala", "answers": 1, "votes": 0, "views": 28, "url": "https://stackoverflow.com/questions/43152704/search-and-replace-text-using-regex-in-intellij"}, {"short_description": "\r\n            In my TestSpec class I have bunch of properties and its starting to be crowded, something like:\n\nimplicit val formats: Formats = DefaultFormats\n\n  val client: WSClient = app.injector.instanceOf[...\r\n        ", "title": "convenient way to take out class members to external class or trait?", "tag": "scala", "answers": 1, "votes": 0, "views": 33, "url": "https://stackoverflow.com/questions/43152013/convenient-way-to-take-out-class-members-to-external-class-or-trait"}, {"short_description": "\r\n            I have a model class im getting back from an api inside my servcie, and when I return it to some client I want to use my own model to keep it simpler and cleaner for the client.\n\nexample :\n\ncase class ...\r\n        ", "title": "What would be the best way in scala to convert between case classes?", "tag": "scala", "answers": 0, "votes": 0, "views": 66, "url": "https://stackoverflow.com/questions/43151618/what-would-be-the-best-way-in-scala-to-convert-between-case-classes"}, {"short_description": "\r\n            Following is the snippet of code I was going thru a scala book.\nOne of the parameter of the Car class is \"def color: String\"\n\nI didn't understand. \"def\" is a keyword to define a method. how can that ...\r\n        ", "title": "can we have methods as arguments in a class definition?", "tag": "scala", "answers": 0, "votes": 0, "views": 41, "url": "https://stackoverflow.com/questions/43151529/can-we-have-methods-as-arguments-in-a-class-definition"}, {"short_description": "\r\n            I don't actually know what to call this question. The title presented was the best I could come up with.\n\nWe are currently working with functional programming in Scala in school, and every so often ...\r\n        ", "title": "Type aliasing in Scala", "tag": "scala", "answers": 0, "votes": -1, "views": 57, "url": "https://stackoverflow.com/questions/43151251/type-aliasing-in-scala"}, {"short_description": "\r\n            So, let's say I have the following two RDDS: \n(These are only the first few rows for each RDD) \n\nRDD1: \n\nTime                   Temp \n2014-08-12 13:20:00    22\n2014-08-12 13:21:00    24\n2014-08-12 13:...\r\n        ", "title": "How to combine two RDDs in Spark (Scala)? [duplicate]", "tag": "scala", "answers": 0, "votes": 0, "views": 36, "url": "https://stackoverflow.com/questions/43151060/how-to-combine-two-rdds-in-spark-scala"}, {"short_description": "\r\n            I have a controller method that extract the request from the client to ModelOne, and I need to change this model one and build it up to a bigger model lets call it ModelTwo so I can sent it to another ...\r\n        ", "title": "how to efficiently build up complex case class in my app flow?", "tag": "scala", "answers": 2, "votes": 0, "views": 26, "url": "https://stackoverflow.com/questions/43150751/how-to-efficiently-build-up-complex-case-class-in-my-app-flow"}, {"short_description": "\r\n            I have a hive table in SerDe format.  One of the columns in a named struct that is probably buried as JSON by SerDe.  For one of these columns I would like to pull out the column as a json string. \n\n...\r\n        ", "title": "getting json string output from hive column with underlying SerDe format in spark scala [closed]", "tag": "scala", "answers": 0, "votes": -2, "views": 14, "url": "https://stackoverflow.com/questions/43150540/getting-json-string-output-from-hive-column-with-underlying-serde-format-in-spar"}, {"short_description": "\r\n            Scala's Type Info from the View menu and by pressing ctrl-shift-p has just stopped working. I press and nothing appears ever. I upgraded the IDE and the plugin but it doesn't make a difference. Any ...\r\n        ", "title": "Intellij Scala Type Info stopped working", "tag": "scala", "answers": 1, "votes": 0, "views": 61, "url": "https://stackoverflow.com/questions/43149611/intellij-scala-type-info-stopped-working"}, {"short_description": "\r\n            java.sql.SQLException: [Cloudera]HiveJDBCDriver Error initialized or created transport for authentication: CONN_KERBEROS_AUTHENTICATION_ERROR_GET_JAASCONFIGURE.\n        at com.cloudera.hiveserver2....\r\n        ", "title": "connect to hive using JDBC in a secured kerberos cluster using keytab - CONN_KERBEROS_AUTHENTICATION_ERROR_GET_JAASCONFIGURE [closed]", "tag": "scala", "answers": 0, "votes": -3, "views": 21, "url": "https://stackoverflow.com/questions/43149590/connect-to-hive-using-jdbc-in-a-secured-kerberos-cluster-using-keytab-conn-ker"}, {"short_description": "\r\n            Being new to Scala, I have created an Object (singleton). and assinged two different variables to that object as shown below. Both of them show me the same hashcode. Because \"School\" is a singleton. ...\r\n        ", "title": "Two objects having same hashcode means they are referring to same object ..right?", "tag": "scala", "answers": 3, "votes": 0, "views": 37, "url": "https://stackoverflow.com/questions/43149388/two-objects-having-same-hashcode-means-they-are-referring-to-same-object-right"}, {"short_description": "\r\n            It might become silly but I have question regarding to Scala Stream evaluation in immutable fashion.\n\nLets say I have a Stream like this (All lines executed in repl);\n\nval a = Stream(1,2,3,4,5,6,7,8,9,...\r\n        ", "title": "How Immutability is Achieved in Scala Streams?", "tag": "scala", "answers": 2, "votes": 1, "views": 69, "url": "https://stackoverflow.com/questions/43149219/how-immutability-is-achieved-in-scala-streams"}, {"short_description": "\r\n            I am trying to send a request to remote actor using ask pattern. The local actor recieves some value and it performs some task on it and updates it.\nThen when local actor try to send back the updated ...\r\n        ", "title": "Scala Akka actors, ask pattern, dead letters encountered while sending reply", "tag": "scala", "answers": 1, "votes": 0, "views": 36, "url": "https://stackoverflow.com/questions/43144728/scala-akka-actors-ask-pattern-dead-letters-encountered-while-sending-reply"}, {"short_description": "\r\n            For example I have this simplified model where timestamp and duration both represent seconds.\n\ncase class Item(id: Int, : Long, duration: Int)\r\nval max_timestmap: Long = ???\nval stmt = items.filter(x =...\r\n        ", "title": "How to filter records with arithmetic operation on columns of different type in Slick 3", "tag": "scala", "answers": 2, "votes": 0, "views": 41, "url": "https://stackoverflow.com/questions/43144416/how-to-filter-records-with-arithmetic-operation-on-columns-of-different-type-in"}, {"short_description": "\r\n            I am trying to encode a few classes into json strings, however no matter what I try, my classes do not seem to be able to find an implicit encoder for the case classes I am using.\n\nHere's the smallest ...\r\n        ", "title": "Circe cannot find implicit encoder", "tag": "scala", "answers": 1, "votes": 0, "views": 30, "url": "https://stackoverflow.com/questions/43143430/circe-cannot-find-implicit-encoder"}, {"short_description": "\r\n            I have an RDD which has maps as its elements. I cannot use RDD.get, of course. So, as of now, I do the following to get values for keys from this map:\n\nval x = RDD.collect().flatten.toMap\r\nand then\n\nx....\r\n        ", "title": "Getting values of keys from a rdd of maps in scala", "tag": "scala", "answers": 2, "votes": 0, "views": 42, "url": "https://stackoverflow.com/questions/43143238/getting-values-of-keys-from-a-rdd-of-maps-in-scala"}, {"short_description": "\r\n            I was looking for a data type for asynchronous operations.\n\nI found that scalaz.ContT[Trampoline, Unit, ?] supports all features in scalaz.concurrent.Future, in addition of BindRec.\n\nThough, there are ...\r\n        ", "title": "What's the benefit of scalaz.concurrent.Future, in comparison to scalaz.ContT[Trampoline, Unit, ?]", "tag": "scala", "answers": 0, "votes": 4, "views": 276, "url": "https://stackoverflow.com/questions/43143171/whats-the-benefit-of-scalaz-concurrent-future-in-comparison-to-scalaz-contttr"}, {"short_description": "\r\n            I'm creating data frame with this code:\n\n  val data = List(\n    List(444.1235D),\n    List(67.5335D),\n    List(69.5335D),\n    List(677.5335D),\n    List(47.5335D),\n    List(null)\n  )\n\n  val rdd = ...\r\n        ", "title": "Spark dataset reduce with null values?", "tag": "scala", "answers": 0, "votes": 0, "views": 51, "url": "https://stackoverflow.com/questions/43142513/spark-dataset-reduce-with-null-values"}, {"short_description": "\r\n            Hello I have this scala object and I want to run the code in sample function using the shell with scala:\n\nobject SampleObject{ \n    def sample(){\n\n         val data = Array(1, 2, 3, 4, 5)\n         ...\r\n        ", "title": "Error: value is not a member of object using Scala on the shell", "tag": "scala", "answers": 1, "votes": 0, "views": 69, "url": "https://stackoverflow.com/questions/43141598/error-value-is-not-a-member-of-object-using-scala-on-the-shell"}]